{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ygygy2022/7130ict/blob/main/Fashion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2nNDHfc8S62"
      },
      "source": [
        "# Image Classification by MLP - Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md1GmUiV8S63"
      },
      "source": [
        "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXCImONe8S64"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6kpBtGG8S64",
        "outputId": "2778eb58-8178-4ec0-febc-4d4fd3fc2df2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "#TODO: load dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#TODO: Resample the dataset if needed\n",
        "#X_train = ...\n",
        "#y_train = ...\n",
        "#X_test = ...\n",
        "#y_test = ...\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-vaAT7G8S65"
      },
      "source": [
        "This dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2qY1iQl8S65"
      },
      "source": [
        "Now begin by exploring the data. Try to display some images with the associated label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "X2GVbyIb8S66",
        "outputId": "2739b783-3c1f-4c86-84a9-83526efa45c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "# np.random.seed(0)\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx],cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvwiyhxD8S66"
      },
      "source": [
        "**Before going further**: what methods could you use to perform such a classification task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKql6vqh8S66"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl1ShjYk8S66"
      },
      "source": [
        "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
        "\n",
        "Hint: you can use the Keras function `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONL4FLDv8S66",
        "outputId": "5480fa74-229c-4bb0-b2f1-59cb7dd88a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 784)\n"
          ]
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "# TODO: reshape the image data (2D array) into input 1D array for a neural network\n",
        "print(np.shape(X_train_norm))\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0],np.prod(X_train_norm.shape[1:]))\n",
        "print(np.shape(X_train_norm))\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0],np.prod(X_test_norm.shape[1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dJg-JYC8S66"
      },
      "source": [
        "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9wLPsOO8S66",
        "outputId": "69ec84fd-59f5-4d6d-dbd1-75c4963e2cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def my_model(input_dim):\n",
        "    # Create the Sequential object\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add 2 dense layers with 10 neurons each using sigmoid or relu activation\n",
        "    model.add(Dense(10,input_dim=input_dim, activation= \"sigmoid\"))\n",
        "    model.add(Dense(10,activation= \"sigmoid\"))\n",
        "    # Add the output layer with one unit: the predicted result\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "my_model(X_train_norm.shape[1]).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l3-6d_I8S67"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdTagolA8S67",
        "outputId": "2bb79961-83f9-4f5d-99a2-4e83b908e345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 4s 5ms/step - loss: 1.9226 - accuracy: 0.4110\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.3455 - accuracy: 0.6438\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 1.0202 - accuracy: 0.6938\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.8316 - accuracy: 0.7560\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.7968\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.6112 - accuracy: 0.8055\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5609 - accuracy: 0.8134\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5277 - accuracy: 0.8231\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5038 - accuracy: 0.8314\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4842 - accuracy: 0.8379\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4695 - accuracy: 0.8433\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4559 - accuracy: 0.8477\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4456 - accuracy: 0.8499\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4373 - accuracy: 0.8524\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4296 - accuracy: 0.8545\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4226 - accuracy: 0.8561\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4157 - accuracy: 0.8589\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4106 - accuracy: 0.8592\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4067 - accuracy: 0.8611\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4024 - accuracy: 0.8623\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3980 - accuracy: 0.8630\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3954 - accuracy: 0.8634\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3906 - accuracy: 0.8652\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3887 - accuracy: 0.8654\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3854 - accuracy: 0.8668\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3828 - accuracy: 0.8667\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3802 - accuracy: 0.8679\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3774 - accuracy: 0.8685\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3757 - accuracy: 0.8694\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3734 - accuracy: 0.8697\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8701\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3691 - accuracy: 0.8708\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3674 - accuracy: 0.8705\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3655 - accuracy: 0.8716\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3639 - accuracy: 0.8723\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3618 - accuracy: 0.8735\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3609 - accuracy: 0.8727\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3582 - accuracy: 0.8742\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3575 - accuracy: 0.8744\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3557 - accuracy: 0.8741\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3543 - accuracy: 0.8754\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3525 - accuracy: 0.8754\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3519 - accuracy: 0.8762\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3497 - accuracy: 0.8769\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3487 - accuracy: 0.8767\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3472 - accuracy: 0.8777\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8774\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3438 - accuracy: 0.8786\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3436 - accuracy: 0.8790\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3428 - accuracy: 0.8788\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3408 - accuracy: 0.8792\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3405 - accuracy: 0.8792\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8793\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3386 - accuracy: 0.8792\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3366 - accuracy: 0.8803\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8808\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3349 - accuracy: 0.8812\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8818\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3331 - accuracy: 0.8824\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3321 - accuracy: 0.8823\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8811\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3306 - accuracy: 0.8825\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3287 - accuracy: 0.8837\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3286 - accuracy: 0.8842\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3275 - accuracy: 0.8836\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3275 - accuracy: 0.8836\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.8844\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3261 - accuracy: 0.8849\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3243 - accuracy: 0.8848\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.8840\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3229 - accuracy: 0.8856\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3229 - accuracy: 0.8869\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3227 - accuracy: 0.8855\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3219 - accuracy: 0.8860\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3204 - accuracy: 0.8864\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3213 - accuracy: 0.8853\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3197 - accuracy: 0.8864\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3189 - accuracy: 0.8876\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3188 - accuracy: 0.8861\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3185 - accuracy: 0.8861\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3171 - accuracy: 0.8867\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3162 - accuracy: 0.8885\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3159 - accuracy: 0.8876\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3153 - accuracy: 0.8876\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3151 - accuracy: 0.8883\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3143 - accuracy: 0.8881\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3146 - accuracy: 0.8879\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3129 - accuracy: 0.8889\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3118 - accuracy: 0.8888\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3115 - accuracy: 0.8895\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3109 - accuracy: 0.8893\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3118 - accuracy: 0.8884\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3104 - accuracy: 0.8906\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3099 - accuracy: 0.8897\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3103 - accuracy: 0.8903\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3099 - accuracy: 0.8901\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3092 - accuracy: 0.8892\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3079 - accuracy: 0.8909\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3072 - accuracy: 0.8909\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3079 - accuracy: 0.8906\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86897f2650>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
        "\n",
        "# TODO: Compile and fit your model\n",
        "model = my_model(X_train_norm.shape[1])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_norm, y_train_cat, epochs=100, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUBhoSTH8S67"
      },
      "source": [
        "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
        "\n",
        "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KAAd3_n8S67",
        "outputId": "93668c76-5206-466b-8138-38638b0d84e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with NN: 0.8907333612442017\n",
            "accuracy on test with NN: 0.8532999753952026\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat, verbose=0)[1])\n",
        "print('accuracy on test with NN:', model.evaluate(X_test_norm, y_test_cat, verbose=0)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfTG0q518S67"
      },
      "source": [
        "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
        "\n",
        "You should try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIOylAr28S67"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFg84cjr8S67"
      },
      "source": [
        "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you can perform hyperparameter optimization using a gridsearch on that model!\n",
        "\n",
        "Fit your model and display the performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZmBZloC18S67"
      },
      "outputs": [],
      "source": [
        "# TODO: Redo the classification with PCA and classification model\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.9)\n",
        "\n",
        "pca.fit(X_train_norm)\n",
        "X_train_pca = pca.transform(X_train_norm)\n",
        "X_test_pca = pca.transform(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OdOCeyl8S68",
        "outputId": "f783ec8c-ec47-45aa-b798-2a144b88a775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score with RF on train 1.0\n",
            "score with RF on train 0.8605\n"
          ]
        }
      ],
      "source": [
        "# TODO: use any classifier you want\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_pca, y_train)\n",
        "\n",
        "print('score with RF on train', rf.score(X_train_pca, y_train))\n",
        "print('score with RF on train', rf.score(X_test_pca, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz8cdDEJ8S68"
      },
      "source": [
        "Are the performances different? Can you explain why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMs_2pq18S68"
      },
      "source": [
        "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}